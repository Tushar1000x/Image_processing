{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tushar1000x/Image_processing/blob/main/IP_LAB_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "# -------------------------------\n",
        "# Step 0: Unzip the Train Dataset if needed\n",
        "# -------------------------------\n",
        "zip_path = 'train_dataset.zip'\n",
        "extract_dir = '.'\n",
        "if not os.path.exists(\"train_dataset\"):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(\"Unzipped train_dataset.zip into\", extract_dir)\n",
        "else:\n",
        "    print(\"train_dataset folder already exists.\")\n",
        "\n",
        "# -------------------------------\n",
        "# Parameters and Setup\n",
        "# -------------------------------\n",
        "data_dir = 'train_dataset'    # Contains folders: landmark1, landmark2, ..., landmark10\n",
        "vocab_size = 250               # Vocabulary size for BoVW (tune based on your dataset) HIGH==>captures more fine details\n",
        "image_size = (2000, 2000)       # Standard resize dimensions\n",
        "\n",
        "# Initialize SIFT extractor\n",
        "sift = cv2.SIFT_create()\n",
        "\n",
        "# -------------------------------\n",
        "# Visualize SIFT Keypoints on a Sample Image\n",
        "# -------------------------------\n",
        "sample_folder = os.path.join(data_dir, 'landmark1')\n",
        "sample_images = [f for f in os.listdir(sample_folder) if f.lower().endswith('.jpg')]\n",
        "if sample_images:\n",
        "    sample_image_path = os.path.join(sample_folder, sample_images[0])\n",
        "    sample_img = cv2.imread(sample_image_path)\n",
        "    sample_img = cv2.resize(sample_img, image_size)\n",
        "    gray_sample = cv2.cvtColor(sample_img, cv2.COLOR_BGR2GRAY)\n",
        "    keypoints, descriptors = sift.detectAndCompute(gray_sample, None)\n",
        "    sample_img_with_keypoints = cv2.drawKeypoints(sample_img, keypoints, None,\n",
        "                                                  flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cv2.cvtColor(sample_img_with_keypoints, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Sample SIFT Keypoints\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No sample image found in landmark1.\")\n",
        "\n",
        "# -------------------------------\n",
        "# Step 1: Collect SIFT Descriptors from All Training Images\n",
        "# -------------------------------\n",
        "descriptors_list = []  # Collect descriptors from each image\n",
        "image_paths = []       # Keep track of each image's path (for later matching)\n",
        "labels = []            # Corresponding labels (folder names)\n",
        "\n",
        "for landmark in os.listdir(data_dir):\n",
        "    landmark_dir = os.path.join(data_dir, landmark)\n",
        "    if not os.path.isdir(landmark_dir):\n",
        "        continue\n",
        "    for filename in os.listdir(landmark_dir):\n",
        "        if not filename.lower().endswith('.jpg'):\n",
        "            continue\n",
        "        img_path = os.path.join(landmark_dir, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.resize(img, image_size)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        kp, des = sift.detectAndCompute(gray, None)\n",
        "        if des is not None:\n",
        "            descriptors_list.append(des)\n",
        "            image_paths.append(img_path)\n",
        "            labels.append(landmark)\n",
        "\n",
        "if len(descriptors_list) == 0:\n",
        "    raise RuntimeError(\"No SIFT descriptors found; please check your dataset images.\")\n",
        "\n",
        "all_descriptors = np.vstack(descriptors_list)\n",
        "print(\"Collected a total of\", all_descriptors.shape[0], \"descriptors.\")\n",
        "\n",
        "# -------------------------------\n",
        "# Step 2: Build the Visual Vocabulary using k-means clustering\n",
        "# -------------------------------\n",
        "kmeans = MiniBatchKMeans(n_clusters=vocab_size, batch_size=vocab_size * 3, random_state=42)\n",
        "kmeans.fit(all_descriptors)\n",
        "print(\"K-means clustering completed. Vocabulary size:\", vocab_size)\n",
        "\n",
        "# -------------------------------\n",
        "# Helper Function: Extract BoVW Features with L2 Normalization\n",
        "# -------------------------------\n",
        "def extract_bovw_features(image_path, sift, kmeans, image_size):\n",
        "    \"\"\"\n",
        "    Extract a normalized Bag-of-Visual-Words histogram from an image.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not read image: {image_path}\")\n",
        "    img = cv2.resize(img, image_size)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    kp, des = sift.detectAndCompute(gray, None)\n",
        "    histogram = np.zeros(kmeans.n_clusters)\n",
        "    if des is not None:\n",
        "        words = kmeans.predict(des)\n",
        "        for w in words:\n",
        "            histogram[w] += 1\n",
        "        norm = np.linalg.norm(histogram)\n",
        "        if norm > 0:\n",
        "            histogram = histogram / norm\n",
        "    return histogram\n",
        "\n",
        "# -------------------------------\n",
        "# Step 3: Build the Training Database (BoVW Histograms)\n",
        "# -------------------------------\n",
        "train_features = []\n",
        "for path in image_paths:\n",
        "    hist = extract_bovw_features(path, sift, kmeans, image_size)\n",
        "    train_features.append(hist)\n",
        "train_features = np.array(train_features)\n",
        "train_labels = np.array(labels)\n",
        "print(\"Training database built with\", len(train_features), \"image histograms.\")\n",
        "\n",
        "# Visualize BoVW Histogram for a Sample Image\n",
        "sample_hist = extract_bovw_features(sample_image_path, sift, kmeans, image_size)\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.bar(range(vocab_size), sample_hist, color='navy')\n",
        "plt.xlabel(\"Visual Word Index\")\n",
        "plt.ylabel(\"Normalized Frequency\")\n",
        "plt.title(\"BoVW Histogram for Sample Image\")\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# Step 4: Updated Classification Function Returning best_idx\n",
        "# -------------------------------\n",
        "def chi2_distance(histA, histB, eps=1e-10):\n",
        "    return 0.5 * np.sum(((histA - histB) ** 2) / (histA + histB + eps))\n",
        "\n",
        "def classify_test_image(test_image_path, sift, kmeans, train_features, train_labels, image_size, distance_metric='chi2'):\n",
        "    \"\"\"\n",
        "    Classify a test image by comparing its BoVW histogram to that of the training set.\n",
        "    Returns the predicted label, the matched image path, the distance array, and the best match index.\n",
        "    \"\"\"\n",
        "    test_hist = extract_bovw_features(test_image_path, sift, kmeans, image_size)\n",
        "\n",
        "    if distance_metric == 'euclidean':\n",
        "        distances = pairwise_distances([test_hist], train_features, metric='euclidean')[0]\n",
        "    elif distance_metric == 'chi2':\n",
        "        distances = np.array([chi2_distance(test_hist, hist) for hist in train_features])\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported distance metric.\")\n",
        "\n",
        "    best_idx = np.argmin(distances)\n",
        "    predicted_label = train_labels[best_idx]\n",
        "    matched_image_path = image_paths[best_idx]\n",
        "    return predicted_label, matched_image_path, distances, best_idx\n",
        "\n",
        "# -------------------------------\n",
        "# Step 5: Visual Evaluation for a Test Image and Feature Matching\n",
        "# -------------------------------\n",
        "# Specify the test image path (update this path to point to your actual test image)\n",
        "test_image_path = 'test.jpg'  # Replace with your test image path\n",
        "\n",
        "try:\n",
        "    predicted_label, matched_img_path, distances, best_idx = classify_test_image(\n",
        "        test_image_path, sift, kmeans, train_features, train_labels, image_size, distance_metric='chi2'\n",
        "    )\n",
        "    print(f\"Predicted Landmark: {predicted_label}\")\n",
        "    print(f\"Closest Matching Training Image: {matched_img_path}\")\n",
        "\n",
        "    # Side-by-Side Visualization: Test Image and Closest Matching Training Image\n",
        "    test_img = cv2.imread(test_image_path)\n",
        "    test_img_resized = cv2.resize(test_img, image_size)\n",
        "    matched_img = cv2.imread(matched_img_path)\n",
        "    matched_img_resized = cv2.resize(matched_img, image_size)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(test_img_resized, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Test Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(matched_img_resized, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Matched Image\\nLabel: {predicted_label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Visualize Distance Metrics for the Test Image Evaluation\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    indices = np.arange(len(distances))\n",
        "    plt.bar(indices, distances, color='teal')\n",
        "    plt.xlabel(\"Training Image Index\")\n",
        "    plt.ylabel(\"Distance (chi-square)\")\n",
        "    plt.title(\"Distance from Test Image to Each Training Image\")\n",
        "    plt.bar(best_idx, distances[best_idx], color='red', label='Best Match')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # -------------------------------\n",
        "    # Step 6: Visualizing SIFT Keypoint Matches\n",
        "    # -------------------------------\n",
        "    # Extract SIFT keypoints and descriptors for the test image\n",
        "    test_gray = cv2.cvtColor(test_img_resized, cv2.COLOR_BGR2GRAY)\n",
        "    kp1, des1 = sift.detectAndCompute(test_gray, None)\n",
        "\n",
        "    # Extract SIFT keypoints and descriptors for the matched training image\n",
        "    matched_gray = cv2.cvtColor(matched_img_resized, cv2.COLOR_BGR2GRAY)\n",
        "    kp2, des2 = sift.detectAndCompute(matched_gray, None)\n",
        "\n",
        "    # Use BFMatcher to find matches between descriptors\n",
        "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "    matches = bf.match(des1, des2)\n",
        "    matches = sorted(matches, key=lambda x: x.distance)  # sort matches by distance\n",
        "\n",
        "    # Draw the top 30 matches\n",
        "    img_matches = cv2.drawMatches(test_img_resized, kp1, matched_img_resized, kp2, matches[:30], None, flags=2)\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"SIFT Keypoint Matches Between Test and Matched Training Images\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error in test image classification:\", e)\n"
      ],
      "metadata": {
        "id": "4cb_qB30L5vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd  # For creating a table\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# -------------------------------\n",
        "# Step 0: Unzip the Test Dataset if needed\n",
        "# -------------------------------\n",
        "test_zip_path = 'test_dataset.zip'\n",
        "test_extract_dir = '.'\n",
        "if not os.path.exists(\"test_dataset\"):\n",
        "    with zipfile.ZipFile(test_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(test_extract_dir)\n",
        "    print(\"Unzipped test_dataset.zip into\", test_extract_dir)\n",
        "else:\n",
        "    print(\"test_dataset folder already exists.\")\n",
        "\n",
        "# -------------------------------\n",
        "# Function Definitions (Assuming these functions are available from previous code)\n",
        "# -------------------------------\n",
        "def extract_bovw_features(image_path, sift, kmeans, image_size):\n",
        "    \"\"\"\n",
        "    Extract a normalized Bag-of-Visual-Words histogram from an image.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not read image: {image_path}\")\n",
        "    img = cv2.resize(img, image_size)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    kp, des = sift.detectAndCompute(gray, None)\n",
        "    histogram = np.zeros(kmeans.n_clusters)\n",
        "    if des is not None:\n",
        "        words = kmeans.predict(des)\n",
        "        for w in words:\n",
        "            histogram[w] += 1\n",
        "        norm = np.linalg.norm(histogram)\n",
        "        if norm > 0:\n",
        "            histogram = histogram / norm\n",
        "    return histogram\n",
        "\n",
        "def chi2_distance(histA, histB, eps=1e-10):\n",
        "    return 0.5 * np.sum(((histA - histB) ** 2) / (histA + histB + eps))\n",
        "\n",
        "def classify_test_image(test_image_path, sift, kmeans, train_features, train_labels, image_size, distance_metric='chi2'):\n",
        "    \"\"\"\n",
        "    Classify a test image by comparing its BoVW histogram to that of the training set.\n",
        "    Returns the predicted label, matched training image path, distances array, and best_idx.\n",
        "    \"\"\"\n",
        "    test_hist = extract_bovw_features(test_image_path, sift, kmeans, image_size)\n",
        "\n",
        "    if distance_metric == 'euclidean':\n",
        "        distances = pairwise_distances([test_hist], train_features, metric='euclidean')[0]\n",
        "    elif distance_metric == 'chi2':\n",
        "        distances = np.array([chi2_distance(test_hist, hist) for hist in train_features])\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported distance metric.\")\n",
        "\n",
        "    best_idx = np.argmin(distances)\n",
        "    predicted_label = train_labels[best_idx]\n",
        "    matched_image_path = image_paths[best_idx]\n",
        "    return predicted_label, matched_image_path, distances, best_idx\n",
        "\n",
        "# -------------------------------\n",
        "# Assumptions:\n",
        "# - The training database and BoVW model have been built.\n",
        "# - Variables 'sift', 'kmeans', 'train_features', 'train_labels', 'image_paths',\n",
        "#   and 'image_size' are already defined in the workspace.\n",
        "# -------------------------------\n",
        "\n",
        "# -------------------------------\n",
        "# Step 1: Predict a Random Test Image from Test Set\n",
        "# -------------------------------\n",
        "test_dataset_path = \"test_dataset\"\n",
        "test_images = []\n",
        "\n",
        "# Collect all test image paths with their ground truth labels (from folder names)\n",
        "for landmark in os.listdir(test_dataset_path):\n",
        "    landmark_dir = os.path.join(test_dataset_path, landmark)\n",
        "    if not os.path.isdir(landmark_dir):\n",
        "        continue\n",
        "    for filename in os.listdir(landmark_dir):\n",
        "        if filename.lower().endswith(\".jpg\"):\n",
        "            full_path = os.path.join(landmark_dir, filename)\n",
        "            test_images.append((full_path, landmark))  # (image_path, actual_label)\n",
        "\n",
        "# Pick a random test image for individual visualization\n",
        "random_test_image_path, true_label = random.choice(test_images)\n",
        "\n",
        "# Classify the random image\n",
        "predicted_label, matched_img_path, distances, best_idx = classify_test_image(\n",
        "    random_test_image_path, sift, kmeans, train_features, train_labels, image_size, distance_metric='chi2'\n",
        ")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ RANDOM TEST IMAGE PREDICTION\")\n",
        "print(f\"Test Image Path: {random_test_image_path}\")\n",
        "print(f\"Actual Label (Folder): {true_label}\")\n",
        "print(f\"Predicted Label       : {predicted_label}\")\n",
        "print(f\"Matched Train Image   : {matched_img_path}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Optional: Visualize Matches and Distance Plot for the Random Test Image\n",
        "# -------------------------------\n",
        "# Read and resize images\n",
        "test_img = cv2.imread(random_test_image_path)\n",
        "test_img = cv2.resize(test_img, image_size)\n",
        "matched_img = cv2.imread(matched_img_path)\n",
        "matched_img = cv2.resize(matched_img, image_size)\n",
        "\n",
        "# Get SIFT keypoints for both images\n",
        "kp1, des1 = sift.detectAndCompute(cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY), None)\n",
        "kp2, des2 = sift.detectAndCompute(cv2.cvtColor(matched_img, cv2.COLOR_BGR2GRAY), None)\n",
        "\n",
        "# Create BFMatcher and compute matches\n",
        "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "matches = bf.match(des1, des2)\n",
        "matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "# Draw the top 30 matches\n",
        "img_matches = cv2.drawMatches(test_img, kp1, matched_img, kp2, matches[:30], None, flags=2)\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Top 30 SIFT Keypoint Matches\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Plot the distance bar chart for the random test image\n",
        "plt.figure(figsize=(12, 4))\n",
        "indices = np.arange(len(distances))\n",
        "plt.bar(indices, distances, color='teal')\n",
        "plt.xlabel(\"Training Image Index\")\n",
        "plt.ylabel(\"Chi-square Distance\")\n",
        "plt.title(\"Test Image Distance to All Training Images\")\n",
        "plt.bar(best_idx, distances[best_idx], color='red', label='Best Match')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# Step 2: Evaluate Accuracy Over Entire Test Dataset and Record Predictions\n",
        "# -------------------------------\n",
        "results = []  # List to record (test_image_path, actual_label, predicted_label)\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "print(f\"\\nðŸ“Š Evaluating Accuracy Over {len(test_images)} Test Images...\\n\")\n",
        "for test_path, actual_label in test_images:\n",
        "    pred_label, _, _, _ = classify_test_image(test_path, sift, kmeans, train_features, train_labels, image_size)\n",
        "    results.append((test_path, actual_label, pred_label))\n",
        "    if pred_label == actual_label:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"âœ… Overall Accuracy: {accuracy:.2f}%  ({correct}/{total} correct predictions)\")\n",
        "\n",
        "# -------------------------------\n",
        "# Step 3: Convert the Results List into a Table and Print\n",
        "# ------------------------------\n",
        "\n",
        "# Assuming 'results' is a list of tuples: (Image Path, Actual Label, Predicted Label)\n",
        "results_df = pd.DataFrame(results, columns=[\"Image Path\", \"Actual Label\", \"Predicted Label\"])\n",
        "\n",
        "# Create a matplotlib figure and axis\n",
        "fig, ax = plt.subplots(figsize=(24, 10))  # Adjust height based on number of rows\n",
        "\n",
        "# Hide axes\n",
        "ax.axis('tight')\n",
        "ax.axis('off')\n",
        "\n",
        "# Create the table\n",
        "table = ax.table(cellText=results_df.values,\n",
        "                 colLabels=results_df.columns,\n",
        "                 cellLoc='center',\n",
        "                 loc='center')\n",
        "\n",
        "# # Customize table style\n",
        "# table.auto_set_font_size(False)\n",
        "# table.set_fontsize(12)\n",
        "table.scale(1, 4)  # scale horizontally and vertically\n",
        "\n",
        "# Change header row properties\n",
        "for (row, col), cell in table.get_celld().items():\n",
        "    if row == 0:  # header row\n",
        "        cell.set_text_props(weight='bold', color='white')\n",
        "        cell.set_facecolor('#4CAF50')  # green header background\n",
        "    else:\n",
        "        # Alternate background color (optional)\n",
        "        if row % 2 == 0:\n",
        "            cell.set_facecolor('#f1f1f2')\n",
        "        else:\n",
        "            cell.set_facecolor('white')\n",
        "\n",
        "plt.title(\"Test Image Predictions\", fontsize=16, pad=20)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "iM0OOtBNrWx_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}